import os
import nltk
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# NLTK kÃ¼tÃ¼phaneleri (Kelime ayÄ±rÄ±cÄ±lar)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    print("[INIT] Downloading NLTK resources...")
    nltk.download('punkt')

def lexical_richness(text):
    """
    Type-Token Ratio (SÃ¶zdizimsel Zenginlik) hesaplar.
    YazarÄ±n kelime daÄŸarcÄ±ÄŸÄ± ne kadar geniÅŸ? Toplam kelime sayÄ±sÄ±na oranla kaÃ§ farklÄ± kelime kullanmÄ±ÅŸ?
    """
    tokens = word_tokenize(text.lower())
    words = [word for word in tokens if word.isalpha()]
    if not words: return 0
    return len(set(words)) / len(words)

def extract_linguistic_dna(ransom_text, suspects_texts):
    """
    TF-IDF ve N-Gram kullanarak metinleri vektÃ¶r uzayÄ±na Ã§evirir ve 
    KosinÃ¼s BenzerliÄŸi (Cosine Similarity) ile karÅŸÄ±laÅŸtÄ±rÄ±r.
    """
    # Ransom Note (Fidye Mektubu) ilk sÄ±raya, ÅŸÃ¼pheliler arkasÄ±na ekleniyor.
    all_documents = [ransom_text] + suspects_texts
    
    # ngram_range=(1, 2) demek: Hem tek kelimelere (Unigram) hem de ikili kelime gruplarÄ±na (Bigram) bak!
    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))
    
    # Metinleri matematiksel matrislere Ã§eviriyoruz
    tfidf_matrix = vectorizer.fit_transform(all_documents)
    
    # Ä°lk matris (Ransom Note) ile diÄŸer matrisleri (ÅÃ¼pheliler) karÅŸÄ±laÅŸtÄ±r
    # [0:1] fidye mektubu, [1:] ÅŸÃ¼phelilerin tamamÄ±
    similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])
    
    return similarities[0]

def main():
    print("=" * 60)
    print("ğŸ§¬ LINGUISTIC DNA FORENSICS V2.0 (STYLOMETRY ENGINE)")
    print("=" * 60)

    # 1. READ RANSOM NOTE
    ransom_path = 'ransom.txt'
    if not os.path.exists(ransom_path):
        print("âŒ 'ransom.txt' bulunamadÄ±!")
        return
        
    with open(ransom_path, 'r', encoding='utf-8') as f:
        ransom_text = f.read()
        
    r_richness = lexical_richness(ransom_text)
    print(f"\nğŸ“„ [TARGET DNA EXTRACTED]")
    print(f"   - Lexical Richness (Kelime Ã‡eÅŸitliliÄŸi): %{r_richness*100:.2f}")
    print("-" * 60)

    # 2. READ SUSPECTS
    suspects_folder = 'suspects'
    if not os.path.exists(suspects_folder):
        print(f"âŒ '{suspects_folder}' klasÃ¶rÃ¼ bulunamadÄ±!")
        return

    suspect_files = [f for f in os.listdir(suspects_folder) if f.endswith('.txt')]
    if not suspect_files:
        print("âŒ ÅÃ¼pheli dosyalarÄ± bulunamadÄ±.")
        return

    suspects_texts = []
    for suspect in suspect_files:
        path = os.path.join(suspects_folder, suspect)
        with open(path, 'r', encoding='utf-8') as f:
            suspects_texts.append(f.read())

    # 3. DNA ANALYSIS (Makine Ã–ÄŸrenmesi Devrede)
    print("ğŸ§  TF-IDF ve N-Gram Analizi BaÅŸlatÄ±lÄ±yor...")
    similarity_scores = extract_linguistic_dna(ransom_text, suspects_texts)

    best_match = None
    highest_score = 0

    print("\nğŸ” ANALÄ°Z SONUÃ‡LARI:")
    for idx, score in enumerate(similarity_scores):
        suspect_name = suspect_files[idx]
        s_richness = lexical_richness(suspects_texts[idx])
        
        # YÃ¼zdelik dilime Ã§eviriyoruz
        match_percentage = score * 100
        
        print(f"\nğŸ‘¤ SUSPECT: {suspect_name}")
        print(f"   - Lexical Richness: %{s_richness*100:.2f}")
        print(f"   ğŸ‘‰ DNA EÅLEÅME ORANI: %{match_percentage:.2f} (Daha yÃ¼ksek daha iyi)")
        
        if match_percentage > highest_score:
            highest_score = match_percentage
            best_match = suspect_name

    print("=" * 60)
    if highest_score > 0:
        print(f"ğŸš¨ KESÄ°NLEÅMÄ°Å HEDEF: {best_match} (%{highest_score:.2f} Benzerlik)")
    else:
        print("â“ Yeterli DNA eÅŸleÅŸmesi bulunamadÄ±.")
    print("=" * 60)

if __name__ == "__main__":
    main()